{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Duplicate Question Pair Detection using Deep Learning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from multiprocessing import cpu_count\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from tensorflow.contrib.metrics import streaming_accuracy as accuracy\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), reduction_indices=2))\n",
    "    length = tf.reduce_sum(used, reduction_indices=1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length\n",
    "def rmse_loss(outputs, targets):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(tf.sub(targets, outputs))))\n",
    "def activate(outputs, weight_shape, bias_shape, activation=tf.nn.softmax):\n",
    "    weights = tf.get_variable(\n",
    "        \"weights\", shape=weight_shape, initializer=tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(\"biases\", shape=bias_shape,\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "    result = activation(tf.matmul(outputs, weights) + biases)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = np.load('data/embed.npz')['embed']\n",
    "batch_size = 10\n",
    "max_length = 237\n",
    "dim = 200\n",
    "reg_lambda = 0.0001\n",
    "is_train=False\n",
    "resume_from_checkpoint=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:52<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() as graph:\n",
    "    embeds = tf.constant(vec, dtype=tf.float32)\n",
    "    input1 = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int64)\n",
    "    input2 = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int64)\n",
    "    target = tf.placeholder(shape=[batch_size], dtype=tf.float32)\n",
    "    input1_embed = tf.nn.embedding_lookup(embeds, input1)\n",
    "    input2_embed = tf.nn.embedding_lookup(embeds, input2)\n",
    "    \n",
    "    \n",
    "    cell1 = tf.nn.rnn_cell.GRUCell(dim)\n",
    "    cell2 = tf.nn.rnn_cell.GRUCell(dim)\n",
    "    \n",
    "    with tf.variable_scope('gru1') as scope1:\n",
    "        o11, _ = tf.nn.dynamic_rnn(cell=cell1, inputs=input1_embed,\n",
    "                        sequence_length=length(input1_embed), dtype=tf.float32)\n",
    "        scope1.reuse_variables()\n",
    "        o21, _ = tf.nn.dynamic_rnn(cell=cell1, inputs=input2_embed,\n",
    "                        sequence_length=length(input2_embed), dtype=tf.float32)\n",
    "        \n",
    "    with tf.variable_scope('gru2') as scope2:\n",
    "        o12, s12 = tf.nn.dynamic_rnn(cell=cell2, inputs=o11, sequence_length=length(input1_embed), dtype=tf.float32)\n",
    "        scope2.reuse_variables()\n",
    "        o22, s22 = tf.nn.dynamic_rnn(cell=cell2, inputs=o21, sequence_length=length(input2_embed), dtype=tf.float32)\n",
    "        \n",
    "        d = tf.concat(1, [tf.abs(tf.sub(s12, s22)), tf.mul(s12, s22)])\n",
    "    preds = tf.squeeze(activate(d, [dim * 2, 1], [1], activation=tf.nn.sigmoid))\n",
    "    loss = - tf.reduce_mean (target * tf.log(preds) + (1 - target) * tf.log(1 - preds)) +\\\n",
    "        tf.reduce_sum([reg_lambda * tf.nn.l2_loss(x) for x in tf.trainable_variables()])\n",
    "    \n",
    "#     acc, update_op = accuracy(preds >= 0.5, target)\n",
    "    optimize_op = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        if resume_from_checkpoint:\n",
    "            saver = tf.train.import_meta_graph('saves/model.ckpt.meta')\n",
    "            saver.restore(sess, tf.train.latest_checkpoint('./saves'))\n",
    "        else:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        if not is_train:\n",
    "            p, t = [], []\n",
    "            for i in trange(1500, 2000):\n",
    "                batch_data = np.load('data/'+str(i)+'.npz')\n",
    "                a, b, c = batch_data['ques1'], batch_data['ques2'], batch_data['label']\n",
    "                p.extend(sess.run(preds,  {input1:a, input2:b, target:c}))\n",
    "                t.extend(c)\n",
    "            p = (np.array(p) >= 0.5).astype(np.int32)\n",
    "            t = np.array(t).astype(np.int32)\n",
    "            print(accuracy_score(p, t))\n",
    "        else: \n",
    "            p, t = [], []\n",
    "            for i in trange(1500):\n",
    "                batch_data = np.load('data/'+str(i)+'.npz')\n",
    "                a, b, c = batch_data['ques1'], batch_data['ques2'], batch_data['label']\n",
    "                _, x = sess.run([optimize_op, preds], {input1: a, input2:b, target: c})\n",
    "                p.extend(x)\n",
    "                t.extend(c)\n",
    "                if i % 100 == 0:\n",
    "                    saver.save(sess, 'saves/model.ckpt')\n",
    "                    p = (np.array(p) >= 0.5).astype(np.int32)\n",
    "                    t = np.array(t).astype(np.int32)\n",
    "                    print(accuracy_score(p, t))\n",
    "                    p, t = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
